{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Ensemble_8.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ym4iNNvHFSye",
        "yCkiOugqFlxy",
        "yQ66p8sBFyJZ",
        "WL1yD-CWGEz5",
        "56Mxce5IGFFl",
        "uAovcr5RGFUk",
        "I_XE8Fw6GFkN"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "021d048fe43d4b308d098cea36f0bbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a6749daba59a430c963cb43ac45eb87c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3afb6248edb748b28d56863b2aa53bbb",
              "IPY_MODEL_2bd6949aea8549be9a7c899e816dfdd8"
            ]
          }
        },
        "a6749daba59a430c963cb43ac45eb87c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3afb6248edb748b28d56863b2aa53bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_05ce09ea8ab4488a847f213314a15e84",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fdc4a7fb62a43b483f08ad79250a197"
          }
        },
        "2bd6949aea8549be9a7c899e816dfdd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4027603bf3c04d919a1f1ded9d7a334a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 763kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfa69b699bfd44cf89ab9e664f88f6ce"
          }
        },
        "05ce09ea8ab4488a847f213314a15e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fdc4a7fb62a43b483f08ad79250a197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4027603bf3c04d919a1f1ded9d7a334a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfa69b699bfd44cf89ab9e664f88f6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKH1hJv1FO6E",
        "colab_type": "text"
      },
      "source": [
        "# Deep Self Ensemble: 8 Way\n",
        "\n",
        "Train a DNN on the imput text to learn which model performs best on given questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym4iNNvHFSye",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Set up environment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PELCzWSFS_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports \n",
        "\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from collections import Counter\n",
        "from itertools import groupby\n",
        "import pandas as pd\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAfoMreFFTPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "4889dbd9-5373-49af-88e1-412cf89092c2"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 29.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 19.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 57.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b38bb60ba74046287c85b66265b8fd418342bd7bc8d2f61a23c0be204c36ac79\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rvtt8f0FTdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65,
          "referenced_widgets": [
            "021d048fe43d4b308d098cea36f0bbd4",
            "a6749daba59a430c963cb43ac45eb87c",
            "3afb6248edb748b28d56863b2aa53bbb",
            "2bd6949aea8549be9a7c899e816dfdd8",
            "05ce09ea8ab4488a847f213314a15e84",
            "7fdc4a7fb62a43b483f08ad79250a197",
            "4027603bf3c04d919a1f1ded9d7a334a",
            "dfa69b699bfd44cf89ab9e664f88f6ce"
          ]
        },
        "outputId": "f0453b9f-a069-43fd-f233-cb28b58d2da5"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "021d048fe43d4b308d098cea36f0bbd4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLhEt6tTFbpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "4a493894-f760-4c9a-c01e-a4c28d015980"
      },
      "source": [
        "#This will clone the BERT Repo\n",
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 317.20 KiB | 1.81 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTaGQw23Fck2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ba4ceb66-d402-4683-8f92-264564865927"
      },
      "source": [
        "#Make sure were in the right place\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbert\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFiGO8AZFcnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "042892f2-a12c-408a-a6dc-25c0a9af0283"
      },
      "source": [
        "# Move to BERT folder \n",
        "%cd bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIEWeQX2Fjns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "691b09a8-6cc0-4919-8728-316cbc4a0b38"
      },
      "source": [
        "#Download the SQUAD train and dev dataset\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-13 17:07:34--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.110.153, 185.199.111.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M  94.2MB/s    in 0.4s    \n",
            "\n",
            "2020-07-13 17:07:34 (94.2 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2020-07-13 17:07:35--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-07-13 17:07:35 (36.1 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCkiOugqFlxy",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Extract the Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRm5jE9PFl9Q",
        "colab_type": "text"
      },
      "source": [
        "Need to Extract:\n",
        "*   Question\n",
        "*   Context\n",
        "\n",
        "Then add the [CLS] and [SEP] tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Zx0mCpFrR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will be used to get the full answer list. \n",
        "def extract_question_text(data):\n",
        "    text = []\n",
        "    for i in range(len(data['data'])):\n",
        "        paragraphs = len(data['data'][i]['paragraphs'])\n",
        "        for j in range(paragraphs):\n",
        "            qas = len(data['data'][i]['paragraphs'][j]['qas'])\n",
        "            context = data['data'][i]['paragraphs'][j]['context']\n",
        "            for k in range(qas):\n",
        "              question = data['data'][i]['paragraphs'][j]['qas'][k]['question']\n",
        "              text.append([question, context])\n",
        "    return text\n",
        "\n",
        "# Need a helper function to open each file\n",
        "def open_json(path):\n",
        "    with open(path) as json_file:\n",
        "        temp_json = json.load(json_file)\n",
        "        return temp_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq3cagVwFtFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cb0a82cb-a35b-4011-c43d-b7afd0959eaf"
      },
      "source": [
        "full_train_data = open_json('train-v2.0.json')\n",
        "full_text = extract_question_text(full_train_data)\n",
        "len(full_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130319"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umcVQTo_FtH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "690ed4d8-5ad5-4c18-c966-e50f55120fca"
      },
      "source": [
        "full_text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['When did Beyonce start becoming popular?',\n",
              " 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ66p8sBFyJZ",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Tokenize the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaQjGZbuFyU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d7c8fefe-43d2-43d0-cfaa-271c5f14006e"
      },
      "source": [
        "def add_special(text_list):\n",
        "  marked_text = []\n",
        "  for ques, context in text_list:\n",
        "    temp_text = \"[CLS] \" + ques + \" [SEP]\" + context\n",
        "    marked_text.append(temp_text)\n",
        "  return marked_text\n",
        "\n",
        "marked_text = add_special(full_text)\n",
        "marked_text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] When did Beyonce start becoming popular? [SEP]Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RX1T6RVFyX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "62794565-8690-499d-b40e-e991d5d6a34e"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in marked_text:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 200,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',\n",
        "                        truncation = True     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "#labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', marked_text[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  [CLS] When did Beyonce start becoming popular? [SEP]Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
            "Token IDs: tensor([  101,  1332,  1225, 24896,  1320,  2093,  1838,  2479,  1927,   136,\n",
            "          102, 24041,   144, 22080, 25384,   118,  5007,   113,   120,   100,\n",
            "          120, 17775,   118,   162, 11414,   118,  1474,   114,   113,  1255,\n",
            "         1347,   125,   117,  2358,   114,  1110,  1126,  1237,  2483,   117,\n",
            "         5523,   117,  1647,  2451,  1105,  3647,   119,  3526,  1105,  2120,\n",
            "         1107,  4666,   117,  2245,   117,  1131,  1982,  1107,  1672,  4241,\n",
            "         1105,  5923,  6025,  1112,   170,  2027,   117,  1105,  3152,  1106,\n",
            "         8408,  1107,  1103,  1523,  3281,  1112,  1730,  2483,  1104,   155,\n",
            "          111,   139,  1873,   118,  1372, 16784,   112,   188,  6405,   119,\n",
            "         2268, 15841,  1118,  1123,  1401,   117, 15112,  5773, 25384,   117,\n",
            "         1103,  1372,  1245,  1141,  1104,  1103,  1362,   112,   188,  1436,\n",
            "          118,  4147,  1873,  2114,  1104,  1155,  1159,   119,  2397, 14938,\n",
            "         1486,  1103,  1836,  1104, 24041,   112,   188,  1963,  1312,   117,\n",
            "        20924,  1193,  1107,  2185,   113,  1581,   114,   117,  1134,  1628,\n",
            "         1123,  1112,   170,  3444,  2360,  4529,   117,  2829,  1421,  8645,\n",
            "         2763,  1105,  2081,  1103,  4192,  4126,  1620,  1295,   118,  1141,\n",
            "         3896,   107, 11722,  1107,  2185,   107,  1105,   107,  6008,  4596,\n",
            "          107,   119,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tyRKBALFybU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fa33441f-6523-45a9-8326-efcfddea9e4d"
      },
      "source": [
        "#write the answers to CSV so I can pick up where I left off. \n",
        "\n",
        "answers_df = pd.read_csv('coded_preds_0.csv')\n",
        "answers_df = answers_df.drop(['Unnamed: 0','keys'], axis = 1)\n",
        "answer_array = answers_df.to_numpy()\n",
        "labels = torch.from_numpy(answer_array)\n",
        "print(labels.dtype)\n",
        "print(input_ids.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.int64\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL1yD-CWGEz5",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Combine with labeled Data to create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-JuGCq3GE9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "26d0ca48-44e3-479f-e350-6f819fa78934"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "117,287 training samples\n",
            "13,032 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiBvtyyhaGsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train_dataset[:][0]\n",
        "y_train = train_dataset[:][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzMGWJQ8fTEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "df0e0125-3d67-48eb-837e-674c885ad107"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  1731,  1242, 16176,  1127,  2536,  1206,  1478,  1105,  1384,\n",
              "          136,   102,  1109,  1148,  5989,  1104,  1103,  1248,   118,  3964,\n",
              "         1449,   117,  3291,  8223, 11192,   118, 26528,  1108,  2536,  1107,\n",
              "         1384,   119,  1135,  1108,  1723,  1118,  1748,  2551, 16176,  1219,\n",
              "         1371,   118,  1349,   117, 11190,  8458,  2918,  5811,   119,   138,\n",
              "         1703,  1104,  1479, 16176,  1127,  2536,  1219,  1142,  4065,   119,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56Mxce5IGFFl",
        "colab_type": "text"
      },
      "source": [
        "### Step 5: Build DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0SQAramaeCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f89943dc-dae2-4be1-a293-c0207abb1f6e"
      },
      "source": [
        "# If there's a GPU available\n",
        "if torch.cuda.is_available():        \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DMc89NRGFMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size) # Evaluate with this batch size."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwypxJ4YaQ0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size, 1000)\n",
        "    self.linear2 = nn.Linear(1000, 1000)\n",
        "    self.linear3 = nn.Linear(1000, 1000)\n",
        "    self.linear4 = nn.Linear(1000, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.linear(x))\n",
        "    x = torch.relu(self.linear2(x))\n",
        "    x = torch.relu(self.linear3(x))\n",
        "    x = torch.sigmoid(self.linear4(x))\n",
        "    return x\n",
        "\n",
        "  def predict(self, x):\n",
        "    pred = self.forward(x)\n",
        "    if pred >= 0.5:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKqFk6uPb1Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(200, 8)\n",
        "model.cuda()\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAovcr5RGFUk",
        "colab_type": "text"
      },
      "source": [
        "### Step 6: Train and predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0li3O5eAGFcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "8f17f3f2-8f2e-4075-ea6a-05121ccee83b"
      },
      "source": [
        "#training loop\n",
        "\n",
        "epochs = 100\n",
        "losses = []\n",
        "x_train, y_train = x_train.cuda(), y_train.cuda()\n",
        "for i in range(epochs):\n",
        "  y_pred = model.forward(x_train.float())\n",
        "  loss = criterion(y_pred, y_train)\n",
        "  #print(\"epoch:\", i, \"loss\", loss.item())\n",
        "  losses.append(loss.item())\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i % 10 == 0:\n",
        "    print(\"epoch:\", i, \"loss\", loss.item())\n",
        "    print('Prediction', y_pred[100])\n",
        "    print(labels[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 loss 0.5546018481254578\n",
            "Prediction tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.6517e-33, 9.9991e-01, 1.0000e+00,\n",
            "        0.0000e+00, 1.0000e+00], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
            "epoch: 10 loss 0.38011565804481506\n",
            "Prediction tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
            "epoch: 20 loss 0.38011565804481506\n",
            "Prediction tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
            "epoch: 30 loss 0.38011565804481506\n",
            "Prediction tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
            "epoch: 40 loss 0.38011565804481506\n",
            "Prediction tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
            "epoch: 50 loss 0.38011565804481506\n",
            "Prediction tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
            "epoch: 60 loss 0.38011565804481506\n",
            "Prediction tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
            "epoch: 70 loss 0.38011565804481506\n",
            "Prediction tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
            "epoch: 80 loss 0.38011565804481506\n",
            "Prediction tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
            "epoch: 90 loss 0.38011565804481506\n",
            "Prediction tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([1, 1, 1, 0, 1, 0, 0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_XE8Fw6GFkN",
        "colab_type": "text"
      },
      "source": [
        "### Step 7\n",
        "Apply the weights to the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIi4HiFwGFs0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "639162d0-aa5f-4105-cfa6-1a07df1fb383"
      },
      "source": [
        "\"\"\"This was unnecessary since all attempts led to a model\n",
        "that converged on predicting 0 for all answers at all times.\n",
        "The results would have been 0% accuracy.  But this inspiried the\n",
        "BERT for multiple choice situation\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This was unnecessary since all attempts led to a model\\nthat converged on predicting 0 for all answers at all times.\\nThe results would have been 0% accuracy.  But this inspiried the\\nBERT for multiple choice situation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}