{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intelligent_voting.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bMOgFK0-pAgO",
        "bYh1YP_spAvt",
        "SaGoRZKipA9R",
        "YGqba9LLpBKs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMOgFK0-pAgO",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Connect to Colab and GCP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2DRgRxhpAok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c35754d1-d503-47b3-9e85-751f4ee5ea5d"
      },
      "source": [
        "#This will clone the BERT Repo\n",
        "\n",
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 317.20 KiB | 7.93 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OqnA0jCqHDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "266da978-a80c-4b38-931c-f436ae993cc7"
      },
      "source": [
        "#Mount my drive so that I can access the split training sets. \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaJxiO-cqMKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "3aefbab8-70c9-494d-f6e0-dc0ecef5786e"
      },
      "source": [
        "# Download the SQUAD train and dev dataset\n",
        "\n",
        "# I do not need the training set since I am using the split version above. \n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "\n",
        "# Still download the Dev set.\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-24 15:18:55--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M  58.3MB/s    in 0.7s    \n",
            "\n",
            "2020-07-24 15:18:56 (58.3 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2020-07-24 15:18:56--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.109.153, 185.199.108.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  18.1MB/s    in 0.2s    \n",
            "\n",
            "2020-07-24 15:18:57 (18.1 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK_waYtvqMM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "4b3c6d05-c5b5-47df-854a-cd27b2ee2663"
      },
      "source": [
        "# Necessary installs so I can mount the files from my bucket onto colab\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   653  100   653    0     0  36277      0 --:--:-- --:--:-- --:--:-- 36277\n",
            "OK\n",
            "105 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 105 not upgraded.\n",
            "Need to get 4,278 kB of archives.\n",
            "After this operation, 12.8 MB of additional disk space will be used.\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 144465 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.30.0_amd64.deb ...\n",
            "Unpacking gcsfuse (0.30.0) ...\n",
            "Setting up gcsfuse (0.30.0) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x2hbDABqMPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7799146a-dbe4-4575-e464-1a4ab7e60083"
      },
      "source": [
        "# Make a folder for the bucket, this will have all of the files inside. \n",
        "\n",
        "!mkdir folderOnColab\n",
        "!gcsfuse thaddeussegura_final_project folderOnColab "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using mount point: /content/folderOnColab\n",
            "Opening GCS connection...\n",
            "Opening bucket...\n",
            "Mounting file system...\n",
            "File system has been successfully mounted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYh1YP_spAvt",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9QJIDQkI8pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports \n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections, functools, operator "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hLVSCUHpA2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are a number of helper functions that will be used below to combine the predictions.\n",
        "\n",
        "#helper function to open json\n",
        "def open_json(path):\n",
        "    with open(path) as json_file:\n",
        "        temp_json = json.load(json_file)\n",
        "        return temp_json\n",
        "\n",
        "#generate a list of file paths.\n",
        "def generate_file_list(n):\n",
        "  list_of_files = []\n",
        "  if n == 1:\n",
        "    for i in range(4):\n",
        "      path = 'folderOnColab/self_ensemble_1/checkpoint'+str(i)+'/nbest_predictions.json'\n",
        "      list_of_files.append(path)\n",
        "  else:\n",
        "    for i in range(n):\n",
        "      path = 'folderOnColab/self_ensemble_'+str(n)+'/'+str(n)+'_way_'+str(i)+'/'+str(n)+'_way_'+str(i)+'_n_preds.json'\n",
        "      list_of_files.append(path)\n",
        "  return list_of_files\n",
        "\n",
        "#extract the predicted text from each of the prediction files.\n",
        "def extract_probs(data, top_n):\n",
        "  new_dict = {}\n",
        "  for key in data:\n",
        "      sub_dict = {}\n",
        "      if len(data[key]) >= top_n:\n",
        "        for i in range(top_n):\n",
        "            sub_dict[data[key][i]['text']] = data[key][i]['probability']\n",
        "        new_dict[key] = sub_dict\n",
        "      else: \n",
        "        sub_dict[data[key][0]['text']] = data[key][0]['probability']\n",
        "        new_dict[key] = sub_dict\n",
        "  return new_dict\n",
        "\n",
        "#Get a dictonary of the keys and the sum of all the probabilities.\n",
        "def sum_probs(dict_list):\n",
        "  new_dict = {}\n",
        "  for key in dict_list[0]:\n",
        "      #go through all dictonaries in the list looking at that key.\n",
        "      #add them into a list of dicts for map reduce\n",
        "      kv_list = []\n",
        "      for dictonary in dict_list:\n",
        "          kv_list.append(dictonary[key])\n",
        "      result = dict(functools.reduce(operator.add, map(collections.Counter, kv_list)))\n",
        "      new_dict[key] = result\n",
        "  return new_dict\n",
        "\n",
        "#take the dictonary of probabilities and return the highest value.\n",
        "# this will be passed into output_predictions to turn it back into a JSON file\n",
        "#So that it can then be evaluated. \n",
        "def get_preds(prob_dict):\n",
        "  predictions = {}\n",
        "  for key in prob_dict:\n",
        "      predictions[key] = max(prob_dict[key].items(), key=operator.itemgetter(1))[0]\n",
        "  return predictions\n",
        "\n",
        "#dump the prediction dict into a json file.\n",
        "def output_predictions(predictions, file_name):\n",
        "    with open(file_name, 'w', encoding = 'utf-8') as json_file:\n",
        "        json.dump(predictions, json_file, ensure_ascii=True)\n",
        "\n",
        "#this is used for factoring in the classification model. \n",
        "def classification_weight(file, weight, n_models):\n",
        "  #append the null prediction to each question in the same\n",
        "  #format used for the other models.\n",
        "  #determine a weight by multipliying the classification by\n",
        "  #an input weight * number of models to normalize.\n",
        "  new_dict = {}\n",
        "  data = open_json(file)\n",
        "  for key in data:\n",
        "    if data[key] == \"\":\n",
        "      sub_dict = {\"\" : 1*weight*n_models}\n",
        "    else:\n",
        "      sub_dict = {\"\" : 0}\n",
        "    new_dict[key] = sub_dict\n",
        "  return new_dict"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--H4qHXaB25O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will loop through the self ensemble models. \n",
        "def full_loop(splits, top_n, file_name):\n",
        "  #get the file list\n",
        "  file_list = generate_file_list(splits)\n",
        "  dict_list = []\n",
        "  #open each file, and append the top n preds with probs for each \n",
        "  for f in file_list:\n",
        "    data = open_json(f)\n",
        "    probs = extract_probs(data, top_n)\n",
        "    dict_list.append(probs)\n",
        "  #map reduce to find sum across keys within each question\n",
        "  prob_dict = sum_probs(dict_list)\n",
        "  #pull out the top selection with the proper key\n",
        "  predictions = get_preds(prob_dict)\n",
        "  #output predictions as the file name\n",
        "  output_predictions(predictions, file_name)\n",
        "\n",
        "#this is if I want to combine multiple models from various folders.\n",
        "def manual_list_loop(file_list, top_n, file_name):\n",
        "  dict_list = []\n",
        "  #open each file, and append the top n preds with probs for each \n",
        "  for f in file_list:\n",
        "    data = open_json(f)\n",
        "    probs = extract_probs(data, top_n)\n",
        "    dict_list.append(probs)\n",
        "  #map reduce to find sum across keys within each question\n",
        "  prob_dict = sum_probs(dict_list)\n",
        "  #pull out the top selection with the proper key\n",
        "  predictions = get_preds(prob_dict)\n",
        "  #output predictions as the file name\n",
        "  output_predictions(predictions, file_name)\n",
        "\n",
        "#this will add classification into the mix. \n",
        "def with_class_loop(file_list, top_n, file_in, weight, out_file_name):\n",
        "  dict_list = []\n",
        "  #open each file, and append the top n preds with probs for each \n",
        "  for f in file_list:\n",
        "    data = open_json(f)\n",
        "    probs = extract_probs(data, top_n)\n",
        "    dict_list.append(probs)\n",
        "  class_dict = classification_weight(file_in, weight, len(dict_list))\n",
        "  dict_list.append(class_dict)\n",
        "  #map reduce to find sum across keys within each question\n",
        "  prob_dict = sum_probs(dict_list)\n",
        "  #pull out the top selection with the proper key\n",
        "  predictions = get_preds(prob_dict)\n",
        "  #output predictions as the file name\n",
        "  output_predictions(predictions, out_file_name)\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ6BXxP0cDzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate for SE4, with top 10 \n",
        "full_loop(4, 10, 'se4_preds.json')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBNrOCBldLui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate for SE8, with top 3 \n",
        "full_loop(8, 3, 'se8_preds.json')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSlBxomNd7Ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate for SE1, with top 10\n",
        "full_loop(1, 10, 'se1_preds.json')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onek-bbwigJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this is for a manual list to check through.  \n",
        "\n",
        "path1 = '/content/folderOnColab/overtrain/nbest_predictions.json'\n",
        "path2 = '/content/folderOnColab/baseline_test2/nbest_predictions.json'\n",
        "path3 = '/content/folderOnColab/baseline_test3/nbest_predictions.json'\n",
        "path4 = '/content/folderOnColab/baseline_test4/nbest_predictions.json'\n",
        "path5 = '/content/folderOnColab/self_ensemble_1/nbest_predictions.json'\n",
        "path_list = [path2, path3, path4, path5]\n",
        "#use the top 10 votes from the models selected above\n",
        "manual_list_loop(path_list, 10, 'man_preds.json')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY2zk7nvjtDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add all of the Self Ensemble models into the prediction.  \n",
        "se4_list = generate_file_list(4)\n",
        "se8_list = generate_file_list(8)\n",
        "for l in se4_list:\n",
        "  path_list.append(l)\n",
        "for l in se8_list:\n",
        "  path_list.append(l)\n",
        "\n",
        "manual_list_loop(path_list, 10, 'man_preds2.json')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E_foOzAa6S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with_class_loop(file_list, top_n, file_in, weight, out_file_name)\n",
        "class_dict = '/content/drive/My Drive/classification_save/preds.json'\n",
        "\n",
        "with_class_loop(path_list, 10, class_dict, 0.1, 'class_preds.json')\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaGoRZKipA9R",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Test weighted voting\n",
        "\n",
        "* Self Ensemble\n",
        "* 4 Way Data Split\n",
        "* 8 Way data split \n",
        "* Misc Models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-bWR5Z9pBDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0e20e1ac-130c-4bd2-b4a0-decd08a264ad"
      },
      "source": [
        "# Clone the SQUAD Repo so that I can get the evaluation file. \n",
        "\n",
        "!git clone https://github.com/white127/SQUAD-2.0-bidaf.git"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SQUAD-2.0-bidaf'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "Receiving objects:   0% (1/125)   \rReceiving objects:   1% (2/125)   \rReceiving objects:   2% (3/125)   \rReceiving objects:   3% (4/125)   \rReceiving objects:   4% (5/125)   \rReceiving objects:   5% (7/125)   \rReceiving objects:   6% (8/125)   \rReceiving objects:   7% (9/125)   \rReceiving objects:   8% (10/125)   \rReceiving objects:   9% (12/125)   \rReceiving objects:  10% (13/125)   \rReceiving objects:  11% (14/125)   \rReceiving objects:  12% (15/125)   \rReceiving objects:  13% (17/125)   \rReceiving objects:  14% (18/125)   \rReceiving objects:  15% (19/125)   \rReceiving objects:  16% (20/125)   \rReceiving objects:  17% (22/125)   \rReceiving objects:  18% (23/125)   \rReceiving objects:  19% (24/125)   \rReceiving objects:  20% (25/125)   \rReceiving objects:  21% (27/125)   \rReceiving objects:  22% (28/125)   \rReceiving objects:  23% (29/125)   \rReceiving objects:  24% (30/125)   \rReceiving objects:  25% (32/125)   \rReceiving objects:  26% (33/125)   \rReceiving objects:  27% (34/125)   \rReceiving objects:  28% (35/125)   \rReceiving objects:  29% (37/125)   \rReceiving objects:  30% (38/125)   \rReceiving objects:  31% (39/125)   \rReceiving objects:  32% (40/125)   \rReceiving objects:  33% (42/125)   \rReceiving objects:  34% (43/125)   \rReceiving objects:  35% (44/125)   \rReceiving objects:  36% (45/125)   \rReceiving objects:  37% (47/125)   \rReceiving objects:  38% (48/125)   \rReceiving objects:  39% (49/125)   \rReceiving objects:  40% (50/125)   \rReceiving objects:  41% (52/125)   \rReceiving objects:  42% (53/125)   \rReceiving objects:  43% (54/125)   \rReceiving objects:  44% (55/125)   \rReceiving objects:  45% (57/125)   \rReceiving objects:  46% (58/125)   \rReceiving objects:  47% (59/125)   \rReceiving objects:  48% (60/125)   \rReceiving objects:  49% (62/125)   \rReceiving objects:  50% (63/125)   \rReceiving objects:  51% (64/125)   \rReceiving objects:  52% (65/125)   \rReceiving objects:  53% (67/125)   \rReceiving objects:  54% (68/125)   \rReceiving objects:  55% (69/125)   \rReceiving objects:  56% (70/125)   \rReceiving objects:  57% (72/125)   \rReceiving objects:  58% (73/125)   \rReceiving objects:  59% (74/125)   \rReceiving objects:  60% (75/125)   \rReceiving objects:  61% (77/125)   \rReceiving objects:  62% (78/125)   \rReceiving objects:  63% (79/125)   \rReceiving objects:  64% (80/125)   \rReceiving objects:  65% (82/125)   \rReceiving objects:  66% (83/125)   \rReceiving objects:  67% (84/125)   \rReceiving objects:  68% (85/125)   \rremote: Total 125 (delta 0), reused 0 (delta 0), pack-reused 125\u001b[K\n",
            "Receiving objects:  69% (87/125)   \rReceiving objects:  70% (88/125)   \rReceiving objects:  71% (89/125)   \rReceiving objects:  72% (90/125)   \rReceiving objects:  73% (92/125)   \rReceiving objects:  74% (93/125)   \rReceiving objects:  75% (94/125)   \rReceiving objects:  76% (95/125)   \rReceiving objects:  77% (97/125)   \rReceiving objects:  78% (98/125)   \rReceiving objects:  79% (99/125)   \rReceiving objects:  80% (100/125)   \rReceiving objects:  81% (102/125)   \rReceiving objects:  82% (103/125)   \rReceiving objects:  83% (104/125)   \rReceiving objects:  84% (105/125)   \rReceiving objects:  85% (107/125)   \rReceiving objects:  86% (108/125)   \rReceiving objects:  87% (109/125)   \rReceiving objects:  88% (110/125)   \rReceiving objects:  89% (112/125)   \rReceiving objects:  90% (113/125)   \rReceiving objects:  91% (114/125)   \rReceiving objects:  92% (115/125)   \rReceiving objects:  93% (117/125)   \rReceiving objects:  94% (118/125)   \rReceiving objects:  95% (119/125)   \rReceiving objects:  96% (120/125)   \rReceiving objects:  97% (122/125)   \rReceiving objects:  98% (123/125)   \rReceiving objects:  99% (124/125)   \rReceiving objects: 100% (125/125)   \rReceiving objects: 100% (125/125), 709.51 KiB | 10.43 MiB/s, done.\n",
            "Resolving deltas:   0% (0/33)   \rResolving deltas:  15% (5/33)   \rResolving deltas:  30% (10/33)   \rResolving deltas:  36% (12/33)   \rResolving deltas:  45% (15/33)   \rResolving deltas:  48% (16/33)   \rResolving deltas:  54% (18/33)   \rResolving deltas:  60% (20/33)   \rResolving deltas:  66% (22/33)   \rResolving deltas:  75% (25/33)   \rResolving deltas:  78% (26/33)   \rResolving deltas:  81% (27/33)   \rResolving deltas:  84% (28/33)   \rResolving deltas:  90% (30/33)   \rResolving deltas:  96% (32/33)   \rResolving deltas: 100% (33/33)   \rResolving deltas: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpUKaSJHqYiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move evaluate-v2.0 into the content folder\n",
        "\n",
        "%mv /content/SQUAD-2.0-bidaf/evaluate-v2.0.py /content/"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4DxXwOlqgsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "731190a2-96ea-4173-a120-0268f74cebbc"
      },
      "source": [
        "# Evaluate the Results. \n",
        "\n",
        "print(\"Results for SE 4, 10 weighted votes\")\n",
        "!python evaluate-v2.0.py dev-v2.0.json se4_preds.json"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for SE 4, 5 weighted votes\n",
            "{\n",
            "  \"exact\": 73.69662258906763,\n",
            "  \"f1\": 77.04776635528744,\n",
            "  \"total\": 11873,\n",
            "  \"HasAns_exact\": 74.59514170040485,\n",
            "  \"HasAns_f1\": 81.30703946294318,\n",
            "  \"HasAns_total\": 5928,\n",
            "  \"NoAns_exact\": 72.80067283431455,\n",
            "  \"NoAns_f1\": 72.80067283431455,\n",
            "  \"NoAns_total\": 5945\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Q4ULEVqgye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "d92465e9-88fa-4be0-d1d2-67485014b17f"
      },
      "source": [
        "print(\"Results for SE 8, 5 weighted votes\")\n",
        "!python evaluate-v2.0.py dev-v2.0.json se8_preds.json "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for SE 8, 5 weighted votes\n",
            "Traceback (most recent call last):\n",
            "  File \"evaluate-v2.0.py\", line 276, in <module>\n",
            "    main()\n",
            "  File \"evaluate-v2.0.py\", line 235, in main\n",
            "    with open(OPTS.pred_file) as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'se8_preds.json'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naqV8CX-e6sd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "3aa21047-28f1-4e87-b0f0-708ad1b117fb"
      },
      "source": [
        "print(\"Results for SE 1, weighted votes\")\n",
        "!python evaluate-v2.0.py dev-v2.0.json se1_preds.json"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for SE 1, weighted votes\n",
            "{\n",
            "  \"exact\": 40.46155141918639,\n",
            "  \"f1\": 44.57816406295368,\n",
            "  \"total\": 11873,\n",
            "  \"HasAns_exact\": 80.97165991902834,\n",
            "  \"HasAns_f1\": 89.2166906071945,\n",
            "  \"HasAns_total\": 5928,\n",
            "  \"NoAns_exact\": 0.0672834314550042,\n",
            "  \"NoAns_f1\": 0.0672834314550042,\n",
            "  \"NoAns_total\": 5945\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R4wv5RYjUVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "1bbd144e-3e5b-46e1-c17c-0eacca4940af"
      },
      "source": [
        "print(\"Results for manual list, weighted votes\")\n",
        "!python evaluate-v2.0.py dev-v2.0.json man_preds.json"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for manual list, weighted votes\n",
            "{\n",
            "  \"exact\": 78.80906257896066,\n",
            "  \"f1\": 81.80238664792371,\n",
            "  \"total\": 11873,\n",
            "  \"HasAns_exact\": 78.67746288798921,\n",
            "  \"HasAns_f1\": 84.67269511990524,\n",
            "  \"HasAns_total\": 5928,\n",
            "  \"NoAns_exact\": 78.94028595458369,\n",
            "  \"NoAns_f1\": 78.94028595458369,\n",
            "  \"NoAns_total\": 5945\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEnIaXo2kRFt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e7aa2c58-40d6-4cc8-eec4-20775dd5d9b2"
      },
      "source": [
        "print(\"Results for All Models, 10 weighted votes\")\n",
        "!python evaluate-v2.0.py dev-v2.0.json man_preds2.json"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for All Models, 10 weighted votes\n",
            "{\n",
            "  \"exact\": 75.0357955024004,\n",
            "  \"f1\": 77.8917591375123,\n",
            "  \"total\": 11873,\n",
            "  \"HasAns_exact\": 76.26518218623482,\n",
            "  \"HasAns_f1\": 81.9852996355741,\n",
            "  \"HasAns_total\": 5928,\n",
            "  \"NoAns_exact\": 73.8099243061396,\n",
            "  \"NoAns_f1\": 73.8099243061396,\n",
            "  \"NoAns_total\": 5945\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGqba9LLpBKs",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Include weight from Sequence Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKWI6mqNpBQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "c5b8cacc-cb29-46c5-d3e5-557a7c33a8f4"
      },
      "source": [
        "print(\"Results for Top Models + classification @ 20% weight\")\n",
        "with_class_loop(path_list, 10, class_dict, 0.20, 'class_preds.json')\n",
        "!python evaluate-v2.0.py dev-v2.0.json class_preds.json \n",
        "\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for Top Models + classification @ 20% weight\n",
            "{\n",
            "  \"exact\": 79.03646930009265,\n",
            "  \"f1\": 81.9903969939297,\n",
            "  \"total\": 11873,\n",
            "  \"HasAns_exact\": 78.18825910931174,\n",
            "  \"HasAns_f1\": 84.10458561216727,\n",
            "  \"HasAns_total\": 5928,\n",
            "  \"NoAns_exact\": 79.88225399495374,\n",
            "  \"NoAns_f1\": 79.88225399495374,\n",
            "  \"NoAns_total\": 5945\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}