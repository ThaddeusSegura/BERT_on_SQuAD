{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SE_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "O3CSRuKkGt2E",
        "hmN18vXMGt4N",
        "CjO9g_QsGt6d",
        "rb9nh89wGt9P",
        "rQIH9OPrGwPq",
        "o_MKLf-2GweR",
        "rlQ3dP6JWUMy",
        "sj66rRTTXPB0",
        "ZNg5M2QNXXbU",
        "luE3KtO7Xb08"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoWyMHHSGxLk",
        "colab_type": "text"
      },
      "source": [
        "# Classification model.\n",
        "\n",
        "\n",
        "*   Take the original training set and classify all questions as 0: Answerable or 1: Unanswerable.\n",
        "*   Use Huggingface transformers: BertForSequenceClassification\n",
        "*   Evaluate results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3CSRuKkGt2E",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: File set up. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su1DUrXVGu0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "bedf3d23-5843-4dfc-ad51-a45cc1280fc3"
      },
      "source": [
        "#Mount my drive so that I can access the split training sets. \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZgZVtUd_27n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "ab1f5891-76ca-495a-c472-12dfc3214a78"
      },
      "source": [
        "# Download the SQUAD train and dev dataset\n",
        "\n",
        "# I will need the full training set.  \n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "\n",
        "# Still download the Dev set.\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-21 13:35:42--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M  58.5MB/s    in 0.7s    \n",
            "\n",
            "2020-07-21 13:35:46 (58.5 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2020-07-21 13:35:47--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.111.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.111.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  17.7MB/s    in 0.2s    \n",
            "\n",
            "2020-07-21 13:35:49 (17.7 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmN18vXMGt4N",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Set up GPU and HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdxA13PHGvLF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8d7d26a3-a1d8-4269-fbc3-50a3597b49fe"
      },
      "source": [
        "# Connect to GPU\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():     \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGJW8ZLIJQ_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "cf033eef-e600-4e36-a166-b0d37fcf1c99"
      },
      "source": [
        "#install transformers. \n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 16.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 35.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 24.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=41061e3e6a520ed2ffd5b162bc5075152a31e3c28bb80abbf27a9fbb9b2192f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjO9g_QsGt6d",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DK03Yg2B319",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Helper Functions\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Need a helper function to open each file\n",
        "def open_json(path):\n",
        "    with open(path) as json_file:\n",
        "        temp_json = json.load(json_file)\n",
        "        return temp_json\n",
        "\n",
        "#this will be code if these are impossible or not. \n",
        "def extract_answer_type(file):\n",
        "    data = open_json(file)\n",
        "    impossible = [] #0 = Possible, 1 = Impossible.\n",
        "    for i in range(len(data['data'])):\n",
        "        paragraphs = len(data['data'][i]['paragraphs'])\n",
        "        for j in range(paragraphs):\n",
        "            qas = len(data['data'][i]['paragraphs'][j]['qas'])\n",
        "            for k in range(qas):\n",
        "                if data['data'][i]['paragraphs'][j]['qas'][k]['is_impossible'] == True:\n",
        "                    impossible.append(1)\n",
        "                else:\n",
        "                    impossible.append(0)\n",
        "    return impossible\n",
        "\n",
        "#this will generate the question data\n",
        "#This is done by combining the question and context.\n",
        "def extract_question(file):\n",
        "    data = open_json(file)\n",
        "    text = []\n",
        "    for i in range(len(data['data'])):\n",
        "        paragraphs = len(data['data'][i]['paragraphs'])\n",
        "        for j in range(paragraphs):\n",
        "            context = data['data'][i]['paragraphs'][j]['context']\n",
        "            qas = len(data['data'][i]['paragraphs'][j]['qas'])\n",
        "            for k in range(qas):\n",
        "                question_id = data['data'][i]['paragraphs'][j]['qas'][k]['id']\n",
        "                question = data['data'][i]['paragraphs'][j]['qas'][k]['question']\n",
        "                text.append([question_id, context, question])\n",
        "    return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUNSETcgCPTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "068c4f30-6aee-41d5-f057-e0f4f3d55192"
      },
      "source": [
        "#create the labels. \n",
        "impossible = extract_answer_type('train-v2.0.json')\n",
        "impossible_df = pd.DataFrame(impossible) \n",
        "impossible_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz0YYZgICa76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b3deaef7-f4f9-47bd-8cb7-2e595bc7b97d"
      },
      "source": [
        "#pull out question data \n",
        "question_text = extract_question('train-v2.0.json')\n",
        "q_df = pd.DataFrame(question_text)\n",
        "q_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          0  ...                                                  2\n",
              "0  56be85543aeaaa14008c9063  ...           When did Beyonce start becoming popular?\n",
              "1  56be85543aeaaa14008c9065  ...  What areas did Beyonce compete in when she was...\n",
              "2  56be85543aeaaa14008c9066  ...  When did Beyonce leave Destiny's Child and bec...\n",
              "3  56bf6b0f3aeaaa14008c9601  ...      In what city and state did Beyonce  grow up? \n",
              "4  56bf6b0f3aeaaa14008c9602  ...         In which decade did Beyonce become famous?\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qluYHyKyEC18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine into one data frame and save to CSV.\n",
        "full_df = pd.concat([q_df, impossible_df], axis = 1, sort = False)\n",
        "full_df.columns = ['id', 'context', 'question', 'impossible']\n",
        "full_df.head()\n",
        "full_df.to_csv('train_classification.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KIWPiuRFPcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bring a copy over into my drive so I can pick up here.\n",
        "\n",
        "%cp -R /content/train_classification.csv /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDFrm_iOKKX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if just picking back off:\n",
        "\n",
        "full_df = pd.read_csv('/content/drive/My Drive/train_classification.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oEo9ZfxK6JB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d061d928-a0bc-406d-ec0e-69b3b41771c9"
      },
      "source": [
        "# ------ FOR A MINI TRAINING SET ------\n",
        "# mini_df = full_df[:10000]\n",
        "\n",
        "# # #Get the lists of sentences and their labels.\n",
        "# contexts = mini_df.context.values\n",
        "# questions = mini_df.question.values\n",
        "# labels = mini_df.impossible.values\n",
        "\n",
        "# ------ FOR THE FULL  TRAINING SET ------\n",
        "contexts = full_df.context.values\n",
        "questions = full_df.question.values\n",
        "labels = full_df.impossible.values\n",
        "\n",
        "\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(130319,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb9nh89wGt9P",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Tokenize the Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3uzT8plGwH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpZjpKvSMPMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "337e78fd-76aa-4c4a-9f97-a06c0de3b0f9"
      },
      "source": [
        "#Because the question and answer are combined, this may result\n",
        "#questions with greater than 512 tokens.\n",
        "\n",
        "# max_len = 0\n",
        "# for sent in contexts:\n",
        "#     input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "#     max_len = max(max_len, len(input_ids))\n",
        "# print('Max sentence length: ', max_len)\n",
        "\n",
        "#Quite a few errors here:  I will have to take the input length to max and truncate. \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When did Beyonce start becoming popular?\n",
            "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cskk7ZOfMPYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "06af5b18-ef85-4157-f6ac-cc96d2f1adbb"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "#Add the question to the front of the contexts \n",
        "for i in range(len(questions)):\n",
        "    text = (str(questions[i])+' '+str(contexts[i]))\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Take to the max length\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',\n",
        "                        truncation = True)\n",
        "\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# # Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', [0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-c27d93ed35b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0mreturn_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# Construct attn. masks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                         truncation = True)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Add the encoded sentence to the list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m         )\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             )\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_split_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    356\u001b[0m                     (\n\u001b[1;32m    357\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                     )\n\u001b[1;32m    360\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    356\u001b[0m                     (\n\u001b[1;32m    357\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                     )\n\u001b[1;32m    360\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;31m# If the token is part of the never_split set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_strip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_split_on_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhitespace_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36m_run_split_on_punc\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_is_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mstart_new_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_is_punctuation\u001b[0;34m(char)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"P\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HhwT3p29VXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "92ab7190-9d64-4856-8a70-e9a521036195"
      },
      "source": [
        "#save the embeddings since this takes a while to run. \n",
        "\n",
        "torch.save(input_ids, '/content/drive/My Drive/input_ids_512c.pt')\n",
        "torch.save(attention_masks, '/content/drive/My Drive/attn_mask_512c.pt')\n",
        "torch.save(labels, '/content/drive/My Drive/labels_512c.pt')\n",
        "\n",
        "print(input_ids.shape)\n",
        "print(attention_masks.shape)\n",
        "print(labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([130319, 512])\n",
            "torch.Size([130319, 512])\n",
            "torch.Size([130319])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDwk0uNxxZBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "261d583d-99b3-476b-e43a-cdacd0822cef"
      },
      "source": [
        "#pick up here by loading them back from my drive. \n",
        "input_ids = torch.load('/content/drive/My Drive/input_ids_512c.pt')\n",
        "attention_masks = torch.load('/content/drive/My Drive/attn_mask_512c.pt')\n",
        "labels = torch.load('/content/drive/My Drive/labels_512c.pt')\n",
        "#sanity check the shape.\n",
        "print(input_ids.size(0))\n",
        "print(attention_masks.size(0))\n",
        "print(labels.size(0))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130319\n",
            "130319\n",
            "130319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcKXN6N2Q1c0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a2316f5-adfb-47ca-84f1-c53f879c5d46"
      },
      "source": [
        "# Going to do some prevalidation so I can watch the training loss\n",
        "# Before I run it on the dev set. \n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "117,287 training samples\n",
            "13,032 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87q2tTIERXiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Up data Loader \n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "#12 is the biggest batch I could get here on a 16GB GPU.\n",
        "batch_size = 12\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size)\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQIH9OPrGwPq",
        "colab_type": "text"
      },
      "source": [
        "### Step 5: Load model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHs5MU2BGwXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd18d891-8b9f-49c3-d7a2-a5c65bd6611f"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\", # Use the 12-layer BERT model.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TclciTB6QYRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set optimizer \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5, # args.learning_rate \n",
        "                  eps = 1e-8 # args.adam_epsilon  \n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilcv__q4QnwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 2\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_MKLf-2GweR",
        "colab_type": "text"
      },
      "source": [
        "### Step 6: Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNPEr_8VR-AZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper functions for training and timing.\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Format as hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GRqP3KDgXWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "47b08d09-7ee3-45a9-a021-cc29e9648e22"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "# this is to check to see what my memory looks like since \n",
        "# memory issues tend to cause this whole thing to crash. \n",
        "\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=8371ad299b82d8a3b25759b229f315337a4098a67b064a33b64d1a457cbb373b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 24.2 GB  |     Proc size: 4.3 GB\n",
            "GPU RAM Free: 15015MB | Used: 1265MB | Util   8% | Total     16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpZVRPsMoZt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "455f2181-ae31-483b-b9ef-4735b49c785a"
      },
      "source": [
        "#full training loop\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels = b_labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  9,774.    Elapsed: 0:00:26.\n",
            "  Batch    80  of  9,774.    Elapsed: 0:00:52.\n",
            "  Batch   120  of  9,774.    Elapsed: 0:01:17.\n",
            "  Batch   160  of  9,774.    Elapsed: 0:01:43.\n",
            "  Batch   200  of  9,774.    Elapsed: 0:02:09.\n",
            "  Batch   240  of  9,774.    Elapsed: 0:02:35.\n",
            "  Batch   280  of  9,774.    Elapsed: 0:03:00.\n",
            "  Batch   320  of  9,774.    Elapsed: 0:03:26.\n",
            "  Batch   360  of  9,774.    Elapsed: 0:03:52.\n",
            "  Batch   400  of  9,774.    Elapsed: 0:04:18.\n",
            "  Batch   440  of  9,774.    Elapsed: 0:04:43.\n",
            "  Batch   480  of  9,774.    Elapsed: 0:05:09.\n",
            "  Batch   520  of  9,774.    Elapsed: 0:05:35.\n",
            "  Batch   560  of  9,774.    Elapsed: 0:06:01.\n",
            "  Batch   600  of  9,774.    Elapsed: 0:06:26.\n",
            "  Batch   640  of  9,774.    Elapsed: 0:06:52.\n",
            "  Batch   680  of  9,774.    Elapsed: 0:07:18.\n",
            "  Batch   720  of  9,774.    Elapsed: 0:07:44.\n",
            "  Batch   760  of  9,774.    Elapsed: 0:08:09.\n",
            "  Batch   800  of  9,774.    Elapsed: 0:08:35.\n",
            "  Batch   840  of  9,774.    Elapsed: 0:09:01.\n",
            "  Batch   880  of  9,774.    Elapsed: 0:09:27.\n",
            "  Batch   920  of  9,774.    Elapsed: 0:09:52.\n",
            "  Batch   960  of  9,774.    Elapsed: 0:10:18.\n",
            "  Batch 1,000  of  9,774.    Elapsed: 0:10:44.\n",
            "  Batch 1,040  of  9,774.    Elapsed: 0:11:10.\n",
            "  Batch 1,080  of  9,774.    Elapsed: 0:11:35.\n",
            "  Batch 1,120  of  9,774.    Elapsed: 0:12:01.\n",
            "  Batch 1,160  of  9,774.    Elapsed: 0:12:27.\n",
            "  Batch 1,200  of  9,774.    Elapsed: 0:12:53.\n",
            "  Batch 1,240  of  9,774.    Elapsed: 0:13:18.\n",
            "  Batch 1,280  of  9,774.    Elapsed: 0:13:44.\n",
            "  Batch 1,320  of  9,774.    Elapsed: 0:14:10.\n",
            "  Batch 1,360  of  9,774.    Elapsed: 0:14:36.\n",
            "  Batch 1,400  of  9,774.    Elapsed: 0:15:01.\n",
            "  Batch 1,440  of  9,774.    Elapsed: 0:15:27.\n",
            "  Batch 1,480  of  9,774.    Elapsed: 0:15:53.\n",
            "  Batch 1,520  of  9,774.    Elapsed: 0:16:19.\n",
            "  Batch 1,560  of  9,774.    Elapsed: 0:16:44.\n",
            "  Batch 1,600  of  9,774.    Elapsed: 0:17:10.\n",
            "  Batch 1,640  of  9,774.    Elapsed: 0:17:36.\n",
            "  Batch 1,680  of  9,774.    Elapsed: 0:18:02.\n",
            "  Batch 1,720  of  9,774.    Elapsed: 0:18:28.\n",
            "  Batch 1,760  of  9,774.    Elapsed: 0:18:53.\n",
            "  Batch 1,800  of  9,774.    Elapsed: 0:19:19.\n",
            "  Batch 1,840  of  9,774.    Elapsed: 0:19:45.\n",
            "  Batch 1,880  of  9,774.    Elapsed: 0:20:10.\n",
            "  Batch 1,920  of  9,774.    Elapsed: 0:20:36.\n",
            "  Batch 1,960  of  9,774.    Elapsed: 0:21:02.\n",
            "  Batch 2,000  of  9,774.    Elapsed: 0:21:28.\n",
            "  Batch 2,040  of  9,774.    Elapsed: 0:21:53.\n",
            "  Batch 2,080  of  9,774.    Elapsed: 0:22:19.\n",
            "  Batch 2,120  of  9,774.    Elapsed: 0:22:45.\n",
            "  Batch 2,160  of  9,774.    Elapsed: 0:23:11.\n",
            "  Batch 2,200  of  9,774.    Elapsed: 0:23:36.\n",
            "  Batch 2,240  of  9,774.    Elapsed: 0:24:02.\n",
            "  Batch 2,280  of  9,774.    Elapsed: 0:24:28.\n",
            "  Batch 2,320  of  9,774.    Elapsed: 0:24:54.\n",
            "  Batch 2,360  of  9,774.    Elapsed: 0:25:19.\n",
            "  Batch 2,400  of  9,774.    Elapsed: 0:25:45.\n",
            "  Batch 2,440  of  9,774.    Elapsed: 0:26:11.\n",
            "  Batch 2,480  of  9,774.    Elapsed: 0:26:37.\n",
            "  Batch 2,520  of  9,774.    Elapsed: 0:27:02.\n",
            "  Batch 2,560  of  9,774.    Elapsed: 0:27:28.\n",
            "  Batch 2,600  of  9,774.    Elapsed: 0:27:54.\n",
            "  Batch 2,640  of  9,774.    Elapsed: 0:28:20.\n",
            "  Batch 2,680  of  9,774.    Elapsed: 0:28:45.\n",
            "  Batch 2,720  of  9,774.    Elapsed: 0:29:11.\n",
            "  Batch 2,760  of  9,774.    Elapsed: 0:29:37.\n",
            "  Batch 2,800  of  9,774.    Elapsed: 0:30:03.\n",
            "  Batch 2,840  of  9,774.    Elapsed: 0:30:28.\n",
            "  Batch 2,880  of  9,774.    Elapsed: 0:30:54.\n",
            "  Batch 2,920  of  9,774.    Elapsed: 0:31:20.\n",
            "  Batch 2,960  of  9,774.    Elapsed: 0:31:46.\n",
            "  Batch 3,000  of  9,774.    Elapsed: 0:32:11.\n",
            "  Batch 3,040  of  9,774.    Elapsed: 0:32:37.\n",
            "  Batch 3,080  of  9,774.    Elapsed: 0:33:03.\n",
            "  Batch 3,120  of  9,774.    Elapsed: 0:33:29.\n",
            "  Batch 3,160  of  9,774.    Elapsed: 0:33:54.\n",
            "  Batch 3,200  of  9,774.    Elapsed: 0:34:20.\n",
            "  Batch 3,240  of  9,774.    Elapsed: 0:34:46.\n",
            "  Batch 3,280  of  9,774.    Elapsed: 0:35:12.\n",
            "  Batch 3,320  of  9,774.    Elapsed: 0:35:37.\n",
            "  Batch 3,360  of  9,774.    Elapsed: 0:36:03.\n",
            "  Batch 3,400  of  9,774.    Elapsed: 0:36:29.\n",
            "  Batch 3,440  of  9,774.    Elapsed: 0:36:55.\n",
            "  Batch 3,480  of  9,774.    Elapsed: 0:37:21.\n",
            "  Batch 3,520  of  9,774.    Elapsed: 0:37:46.\n",
            "  Batch 3,560  of  9,774.    Elapsed: 0:38:12.\n",
            "  Batch 3,600  of  9,774.    Elapsed: 0:38:38.\n",
            "  Batch 3,640  of  9,774.    Elapsed: 0:39:04.\n",
            "  Batch 3,680  of  9,774.    Elapsed: 0:39:29.\n",
            "  Batch 3,720  of  9,774.    Elapsed: 0:39:55.\n",
            "  Batch 3,760  of  9,774.    Elapsed: 0:40:21.\n",
            "  Batch 3,800  of  9,774.    Elapsed: 0:40:47.\n",
            "  Batch 3,840  of  9,774.    Elapsed: 0:41:12.\n",
            "  Batch 3,880  of  9,774.    Elapsed: 0:41:38.\n",
            "  Batch 3,920  of  9,774.    Elapsed: 0:42:04.\n",
            "  Batch 3,960  of  9,774.    Elapsed: 0:42:30.\n",
            "  Batch 4,000  of  9,774.    Elapsed: 0:42:55.\n",
            "  Batch 4,040  of  9,774.    Elapsed: 0:43:21.\n",
            "  Batch 4,080  of  9,774.    Elapsed: 0:43:47.\n",
            "  Batch 4,120  of  9,774.    Elapsed: 0:44:12.\n",
            "  Batch 4,160  of  9,774.    Elapsed: 0:44:38.\n",
            "  Batch 4,200  of  9,774.    Elapsed: 0:45:04.\n",
            "  Batch 4,240  of  9,774.    Elapsed: 0:45:30.\n",
            "  Batch 4,280  of  9,774.    Elapsed: 0:45:56.\n",
            "  Batch 4,320  of  9,774.    Elapsed: 0:46:21.\n",
            "  Batch 4,360  of  9,774.    Elapsed: 0:46:47.\n",
            "  Batch 4,400  of  9,774.    Elapsed: 0:47:13.\n",
            "  Batch 4,440  of  9,774.    Elapsed: 0:47:39.\n",
            "  Batch 4,480  of  9,774.    Elapsed: 0:48:04.\n",
            "  Batch 4,520  of  9,774.    Elapsed: 0:48:30.\n",
            "  Batch 4,560  of  9,774.    Elapsed: 0:48:56.\n",
            "  Batch 4,600  of  9,774.    Elapsed: 0:49:22.\n",
            "  Batch 4,640  of  9,774.    Elapsed: 0:49:47.\n",
            "  Batch 4,680  of  9,774.    Elapsed: 0:50:13.\n",
            "  Batch 4,720  of  9,774.    Elapsed: 0:50:39.\n",
            "  Batch 4,760  of  9,774.    Elapsed: 0:51:05.\n",
            "  Batch 4,800  of  9,774.    Elapsed: 0:51:30.\n",
            "  Batch 4,840  of  9,774.    Elapsed: 0:51:56.\n",
            "  Batch 4,880  of  9,774.    Elapsed: 0:52:22.\n",
            "  Batch 4,920  of  9,774.    Elapsed: 0:52:48.\n",
            "  Batch 4,960  of  9,774.    Elapsed: 0:53:13.\n",
            "  Batch 5,000  of  9,774.    Elapsed: 0:53:39.\n",
            "  Batch 5,040  of  9,774.    Elapsed: 0:54:05.\n",
            "  Batch 5,080  of  9,774.    Elapsed: 0:54:30.\n",
            "  Batch 5,120  of  9,774.    Elapsed: 0:54:56.\n",
            "  Batch 5,160  of  9,774.    Elapsed: 0:55:22.\n",
            "  Batch 5,200  of  9,774.    Elapsed: 0:55:48.\n",
            "  Batch 5,240  of  9,774.    Elapsed: 0:56:14.\n",
            "  Batch 5,280  of  9,774.    Elapsed: 0:56:39.\n",
            "  Batch 5,320  of  9,774.    Elapsed: 0:57:05.\n",
            "  Batch 5,360  of  9,774.    Elapsed: 0:57:31.\n",
            "  Batch 5,400  of  9,774.    Elapsed: 0:57:56.\n",
            "  Batch 5,440  of  9,774.    Elapsed: 0:58:22.\n",
            "  Batch 5,480  of  9,774.    Elapsed: 0:58:48.\n",
            "  Batch 5,520  of  9,774.    Elapsed: 0:59:14.\n",
            "  Batch 5,560  of  9,774.    Elapsed: 0:59:39.\n",
            "  Batch 5,600  of  9,774.    Elapsed: 1:00:05.\n",
            "  Batch 5,640  of  9,774.    Elapsed: 1:00:31.\n",
            "  Batch 5,680  of  9,774.    Elapsed: 1:00:56.\n",
            "  Batch 5,720  of  9,774.    Elapsed: 1:01:22.\n",
            "  Batch 5,760  of  9,774.    Elapsed: 1:01:48.\n",
            "  Batch 5,800  of  9,774.    Elapsed: 1:02:14.\n",
            "  Batch 5,840  of  9,774.    Elapsed: 1:02:40.\n",
            "  Batch 5,880  of  9,774.    Elapsed: 1:03:05.\n",
            "  Batch 5,920  of  9,774.    Elapsed: 1:03:31.\n",
            "  Batch 5,960  of  9,774.    Elapsed: 1:03:57.\n",
            "  Batch 6,000  of  9,774.    Elapsed: 1:04:22.\n",
            "  Batch 6,040  of  9,774.    Elapsed: 1:04:48.\n",
            "  Batch 6,080  of  9,774.    Elapsed: 1:05:14.\n",
            "  Batch 6,120  of  9,774.    Elapsed: 1:05:40.\n",
            "  Batch 6,160  of  9,774.    Elapsed: 1:06:05.\n",
            "  Batch 6,200  of  9,774.    Elapsed: 1:06:31.\n",
            "  Batch 6,240  of  9,774.    Elapsed: 1:06:57.\n",
            "  Batch 6,280  of  9,774.    Elapsed: 1:07:23.\n",
            "  Batch 6,320  of  9,774.    Elapsed: 1:07:48.\n",
            "  Batch 6,360  of  9,774.    Elapsed: 1:08:14.\n",
            "  Batch 6,400  of  9,774.    Elapsed: 1:08:40.\n",
            "  Batch 6,440  of  9,774.    Elapsed: 1:09:06.\n",
            "  Batch 6,480  of  9,774.    Elapsed: 1:09:31.\n",
            "  Batch 6,520  of  9,774.    Elapsed: 1:09:57.\n",
            "  Batch 6,560  of  9,774.    Elapsed: 1:10:23.\n",
            "  Batch 6,600  of  9,774.    Elapsed: 1:10:49.\n",
            "  Batch 6,640  of  9,774.    Elapsed: 1:11:14.\n",
            "  Batch 6,680  of  9,774.    Elapsed: 1:11:40.\n",
            "  Batch 6,720  of  9,774.    Elapsed: 1:12:06.\n",
            "  Batch 6,760  of  9,774.    Elapsed: 1:12:31.\n",
            "  Batch 6,800  of  9,774.    Elapsed: 1:12:57.\n",
            "  Batch 6,840  of  9,774.    Elapsed: 1:13:23.\n",
            "  Batch 6,880  of  9,774.    Elapsed: 1:13:49.\n",
            "  Batch 6,920  of  9,774.    Elapsed: 1:14:14.\n",
            "  Batch 6,960  of  9,774.    Elapsed: 1:14:40.\n",
            "  Batch 7,000  of  9,774.    Elapsed: 1:15:06.\n",
            "  Batch 7,040  of  9,774.    Elapsed: 1:15:32.\n",
            "  Batch 7,080  of  9,774.    Elapsed: 1:15:58.\n",
            "  Batch 7,120  of  9,774.    Elapsed: 1:16:23.\n",
            "  Batch 7,160  of  9,774.    Elapsed: 1:16:49.\n",
            "  Batch 7,200  of  9,774.    Elapsed: 1:17:15.\n",
            "  Batch 7,240  of  9,774.    Elapsed: 1:17:41.\n",
            "  Batch 7,280  of  9,774.    Elapsed: 1:18:06.\n",
            "  Batch 7,320  of  9,774.    Elapsed: 1:18:32.\n",
            "  Batch 7,360  of  9,774.    Elapsed: 1:18:58.\n",
            "  Batch 7,400  of  9,774.    Elapsed: 1:19:24.\n",
            "  Batch 7,440  of  9,774.    Elapsed: 1:19:49.\n",
            "  Batch 7,480  of  9,774.    Elapsed: 1:20:15.\n",
            "  Batch 7,520  of  9,774.    Elapsed: 1:20:41.\n",
            "  Batch 7,560  of  9,774.    Elapsed: 1:21:07.\n",
            "  Batch 7,600  of  9,774.    Elapsed: 1:21:32.\n",
            "  Batch 7,640  of  9,774.    Elapsed: 1:21:58.\n",
            "  Batch 7,680  of  9,774.    Elapsed: 1:22:24.\n",
            "  Batch 7,720  of  9,774.    Elapsed: 1:22:50.\n",
            "  Batch 7,760  of  9,774.    Elapsed: 1:23:16.\n",
            "  Batch 7,800  of  9,774.    Elapsed: 1:23:41.\n",
            "  Batch 7,840  of  9,774.    Elapsed: 1:24:07.\n",
            "  Batch 7,880  of  9,774.    Elapsed: 1:24:33.\n",
            "  Batch 7,920  of  9,774.    Elapsed: 1:24:59.\n",
            "  Batch 7,960  of  9,774.    Elapsed: 1:25:24.\n",
            "  Batch 8,000  of  9,774.    Elapsed: 1:25:50.\n",
            "  Batch 8,040  of  9,774.    Elapsed: 1:26:16.\n",
            "  Batch 8,080  of  9,774.    Elapsed: 1:26:42.\n",
            "  Batch 8,120  of  9,774.    Elapsed: 1:27:07.\n",
            "  Batch 8,160  of  9,774.    Elapsed: 1:27:33.\n",
            "  Batch 8,200  of  9,774.    Elapsed: 1:27:59.\n",
            "  Batch 8,240  of  9,774.    Elapsed: 1:28:25.\n",
            "  Batch 8,280  of  9,774.    Elapsed: 1:28:50.\n",
            "  Batch 8,320  of  9,774.    Elapsed: 1:29:16.\n",
            "  Batch 8,360  of  9,774.    Elapsed: 1:29:42.\n",
            "  Batch 8,400  of  9,774.    Elapsed: 1:30:08.\n",
            "  Batch 8,440  of  9,774.    Elapsed: 1:30:34.\n",
            "  Batch 8,480  of  9,774.    Elapsed: 1:30:59.\n",
            "  Batch 8,520  of  9,774.    Elapsed: 1:31:25.\n",
            "  Batch 8,560  of  9,774.    Elapsed: 1:31:51.\n",
            "  Batch 8,600  of  9,774.    Elapsed: 1:32:17.\n",
            "  Batch 8,640  of  9,774.    Elapsed: 1:32:42.\n",
            "  Batch 8,680  of  9,774.    Elapsed: 1:33:08.\n",
            "  Batch 8,720  of  9,774.    Elapsed: 1:33:34.\n",
            "  Batch 8,760  of  9,774.    Elapsed: 1:34:00.\n",
            "  Batch 8,800  of  9,774.    Elapsed: 1:34:25.\n",
            "  Batch 8,840  of  9,774.    Elapsed: 1:34:51.\n",
            "  Batch 8,880  of  9,774.    Elapsed: 1:35:17.\n",
            "  Batch 8,920  of  9,774.    Elapsed: 1:35:43.\n",
            "  Batch 8,960  of  9,774.    Elapsed: 1:36:09.\n",
            "  Batch 9,000  of  9,774.    Elapsed: 1:36:34.\n",
            "  Batch 9,040  of  9,774.    Elapsed: 1:37:00.\n",
            "  Batch 9,080  of  9,774.    Elapsed: 1:37:26.\n",
            "  Batch 9,120  of  9,774.    Elapsed: 1:37:52.\n",
            "  Batch 9,160  of  9,774.    Elapsed: 1:38:18.\n",
            "  Batch 9,200  of  9,774.    Elapsed: 1:38:43.\n",
            "  Batch 9,240  of  9,774.    Elapsed: 1:39:09.\n",
            "  Batch 9,280  of  9,774.    Elapsed: 1:39:35.\n",
            "  Batch 9,320  of  9,774.    Elapsed: 1:40:01.\n",
            "  Batch 9,360  of  9,774.    Elapsed: 1:40:26.\n",
            "  Batch 9,400  of  9,774.    Elapsed: 1:40:52.\n",
            "  Batch 9,440  of  9,774.    Elapsed: 1:41:18.\n",
            "  Batch 9,480  of  9,774.    Elapsed: 1:41:44.\n",
            "  Batch 9,520  of  9,774.    Elapsed: 1:42:09.\n",
            "  Batch 9,560  of  9,774.    Elapsed: 1:42:35.\n",
            "  Batch 9,600  of  9,774.    Elapsed: 1:43:01.\n",
            "  Batch 9,640  of  9,774.    Elapsed: 1:43:27.\n",
            "  Batch 9,680  of  9,774.    Elapsed: 1:43:52.\n",
            "  Batch 9,720  of  9,774.    Elapsed: 1:44:18.\n",
            "  Batch 9,760  of  9,774.    Elapsed: 1:44:44.\n",
            "  Average training loss: 0.44\n",
            "  Training epcoh took: 1:44:53\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.36\n",
            "  Validation took: 0:03:46\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  9,774.    Elapsed: 0:00:26.\n",
            "  Batch    80  of  9,774.    Elapsed: 0:00:52.\n",
            "  Batch   120  of  9,774.    Elapsed: 0:01:17.\n",
            "  Batch   160  of  9,774.    Elapsed: 0:01:43.\n",
            "  Batch   200  of  9,774.    Elapsed: 0:02:09.\n",
            "  Batch   240  of  9,774.    Elapsed: 0:02:35.\n",
            "  Batch   280  of  9,774.    Elapsed: 0:03:00.\n",
            "  Batch   320  of  9,774.    Elapsed: 0:03:26.\n",
            "  Batch   360  of  9,774.    Elapsed: 0:03:52.\n",
            "  Batch   400  of  9,774.    Elapsed: 0:04:17.\n",
            "  Batch   440  of  9,774.    Elapsed: 0:04:43.\n",
            "  Batch   480  of  9,774.    Elapsed: 0:05:09.\n",
            "  Batch   520  of  9,774.    Elapsed: 0:05:35.\n",
            "  Batch   560  of  9,774.    Elapsed: 0:06:00.\n",
            "  Batch   600  of  9,774.    Elapsed: 0:06:26.\n",
            "  Batch   640  of  9,774.    Elapsed: 0:06:52.\n",
            "  Batch   680  of  9,774.    Elapsed: 0:07:18.\n",
            "  Batch   720  of  9,774.    Elapsed: 0:07:43.\n",
            "  Batch   760  of  9,774.    Elapsed: 0:08:09.\n",
            "  Batch   800  of  9,774.    Elapsed: 0:08:35.\n",
            "  Batch   840  of  9,774.    Elapsed: 0:09:01.\n",
            "  Batch   880  of  9,774.    Elapsed: 0:09:27.\n",
            "  Batch   920  of  9,774.    Elapsed: 0:09:52.\n",
            "  Batch   960  of  9,774.    Elapsed: 0:10:18.\n",
            "  Batch 1,000  of  9,774.    Elapsed: 0:10:44.\n",
            "  Batch 1,040  of  9,774.    Elapsed: 0:11:09.\n",
            "  Batch 1,080  of  9,774.    Elapsed: 0:11:35.\n",
            "  Batch 1,120  of  9,774.    Elapsed: 0:12:01.\n",
            "  Batch 1,160  of  9,774.    Elapsed: 0:12:27.\n",
            "  Batch 1,200  of  9,774.    Elapsed: 0:12:53.\n",
            "  Batch 1,240  of  9,774.    Elapsed: 0:13:18.\n",
            "  Batch 1,280  of  9,774.    Elapsed: 0:13:44.\n",
            "  Batch 1,320  of  9,774.    Elapsed: 0:14:10.\n",
            "  Batch 1,360  of  9,774.    Elapsed: 0:14:36.\n",
            "  Batch 1,400  of  9,774.    Elapsed: 0:15:01.\n",
            "  Batch 1,440  of  9,774.    Elapsed: 0:15:27.\n",
            "  Batch 1,480  of  9,774.    Elapsed: 0:15:53.\n",
            "  Batch 1,520  of  9,774.    Elapsed: 0:16:18.\n",
            "  Batch 1,560  of  9,774.    Elapsed: 0:16:44.\n",
            "  Batch 1,600  of  9,774.    Elapsed: 0:17:10.\n",
            "  Batch 1,640  of  9,774.    Elapsed: 0:17:36.\n",
            "  Batch 1,680  of  9,774.    Elapsed: 0:18:01.\n",
            "  Batch 1,720  of  9,774.    Elapsed: 0:18:27.\n",
            "  Batch 1,760  of  9,774.    Elapsed: 0:18:53.\n",
            "  Batch 1,800  of  9,774.    Elapsed: 0:19:19.\n",
            "  Batch 1,840  of  9,774.    Elapsed: 0:19:44.\n",
            "  Batch 1,880  of  9,774.    Elapsed: 0:20:10.\n",
            "  Batch 1,920  of  9,774.    Elapsed: 0:20:36.\n",
            "  Batch 1,960  of  9,774.    Elapsed: 0:21:02.\n",
            "  Batch 2,000  of  9,774.    Elapsed: 0:21:27.\n",
            "  Batch 2,040  of  9,774.    Elapsed: 0:21:53.\n",
            "  Batch 2,080  of  9,774.    Elapsed: 0:22:19.\n",
            "  Batch 2,120  of  9,774.    Elapsed: 0:22:45.\n",
            "  Batch 2,160  of  9,774.    Elapsed: 0:23:11.\n",
            "  Batch 2,200  of  9,774.    Elapsed: 0:23:36.\n",
            "  Batch 2,240  of  9,774.    Elapsed: 0:24:02.\n",
            "  Batch 2,280  of  9,774.    Elapsed: 0:24:28.\n",
            "  Batch 2,320  of  9,774.    Elapsed: 0:24:53.\n",
            "  Batch 2,360  of  9,774.    Elapsed: 0:25:19.\n",
            "  Batch 2,400  of  9,774.    Elapsed: 0:25:45.\n",
            "  Batch 2,440  of  9,774.    Elapsed: 0:26:11.\n",
            "  Batch 2,480  of  9,774.    Elapsed: 0:26:36.\n",
            "  Batch 2,520  of  9,774.    Elapsed: 0:27:02.\n",
            "  Batch 2,560  of  9,774.    Elapsed: 0:27:28.\n",
            "  Batch 2,600  of  9,774.    Elapsed: 0:27:54.\n",
            "  Batch 2,640  of  9,774.    Elapsed: 0:28:19.\n",
            "  Batch 2,680  of  9,774.    Elapsed: 0:28:45.\n",
            "  Batch 2,720  of  9,774.    Elapsed: 0:29:11.\n",
            "  Batch 2,760  of  9,774.    Elapsed: 0:29:36.\n",
            "  Batch 2,800  of  9,774.    Elapsed: 0:30:02.\n",
            "  Batch 2,840  of  9,774.    Elapsed: 0:30:28.\n",
            "  Batch 2,880  of  9,774.    Elapsed: 0:30:54.\n",
            "  Batch 2,920  of  9,774.    Elapsed: 0:31:19.\n",
            "  Batch 2,960  of  9,774.    Elapsed: 0:31:45.\n",
            "  Batch 3,000  of  9,774.    Elapsed: 0:32:11.\n",
            "  Batch 3,040  of  9,774.    Elapsed: 0:32:36.\n",
            "  Batch 3,080  of  9,774.    Elapsed: 0:33:02.\n",
            "  Batch 3,120  of  9,774.    Elapsed: 0:33:28.\n",
            "  Batch 3,160  of  9,774.    Elapsed: 0:33:54.\n",
            "  Batch 3,200  of  9,774.    Elapsed: 0:34:19.\n",
            "  Batch 3,240  of  9,774.    Elapsed: 0:34:45.\n",
            "  Batch 3,280  of  9,774.    Elapsed: 0:35:11.\n",
            "  Batch 3,320  of  9,774.    Elapsed: 0:35:37.\n",
            "  Batch 3,360  of  9,774.    Elapsed: 0:36:02.\n",
            "  Batch 3,400  of  9,774.    Elapsed: 0:36:28.\n",
            "  Batch 3,440  of  9,774.    Elapsed: 0:36:54.\n",
            "  Batch 3,480  of  9,774.    Elapsed: 0:37:20.\n",
            "  Batch 3,520  of  9,774.    Elapsed: 0:37:45.\n",
            "  Batch 3,560  of  9,774.    Elapsed: 0:38:11.\n",
            "  Batch 3,600  of  9,774.    Elapsed: 0:38:37.\n",
            "  Batch 3,640  of  9,774.    Elapsed: 0:39:03.\n",
            "  Batch 3,680  of  9,774.    Elapsed: 0:39:28.\n",
            "  Batch 3,720  of  9,774.    Elapsed: 0:39:54.\n",
            "  Batch 3,760  of  9,774.    Elapsed: 0:40:20.\n",
            "  Batch 3,800  of  9,774.    Elapsed: 0:40:45.\n",
            "  Batch 3,840  of  9,774.    Elapsed: 0:41:11.\n",
            "  Batch 3,880  of  9,774.    Elapsed: 0:41:37.\n",
            "  Batch 3,920  of  9,774.    Elapsed: 0:42:02.\n",
            "  Batch 3,960  of  9,774.    Elapsed: 0:42:28.\n",
            "  Batch 4,000  of  9,774.    Elapsed: 0:42:54.\n",
            "  Batch 4,040  of  9,774.    Elapsed: 0:43:20.\n",
            "  Batch 4,080  of  9,774.    Elapsed: 0:43:45.\n",
            "  Batch 4,120  of  9,774.    Elapsed: 0:44:11.\n",
            "  Batch 4,160  of  9,774.    Elapsed: 0:44:37.\n",
            "  Batch 4,200  of  9,774.    Elapsed: 0:45:03.\n",
            "  Batch 4,240  of  9,774.    Elapsed: 0:45:28.\n",
            "  Batch 4,280  of  9,774.    Elapsed: 0:45:54.\n",
            "  Batch 4,320  of  9,774.    Elapsed: 0:46:20.\n",
            "  Batch 4,360  of  9,774.    Elapsed: 0:46:45.\n",
            "  Batch 4,400  of  9,774.    Elapsed: 0:47:11.\n",
            "  Batch 4,440  of  9,774.    Elapsed: 0:47:37.\n",
            "  Batch 4,480  of  9,774.    Elapsed: 0:48:03.\n",
            "  Batch 4,520  of  9,774.    Elapsed: 0:48:28.\n",
            "  Batch 4,560  of  9,774.    Elapsed: 0:48:54.\n",
            "  Batch 4,600  of  9,774.    Elapsed: 0:49:20.\n",
            "  Batch 4,640  of  9,774.    Elapsed: 0:49:46.\n",
            "  Batch 4,680  of  9,774.    Elapsed: 0:50:11.\n",
            "  Batch 4,720  of  9,774.    Elapsed: 0:50:37.\n",
            "  Batch 4,760  of  9,774.    Elapsed: 0:51:03.\n",
            "  Batch 4,800  of  9,774.    Elapsed: 0:51:29.\n",
            "  Batch 4,840  of  9,774.    Elapsed: 0:51:54.\n",
            "  Batch 4,880  of  9,774.    Elapsed: 0:52:20.\n",
            "  Batch 4,920  of  9,774.    Elapsed: 0:52:46.\n",
            "  Batch 4,960  of  9,774.    Elapsed: 0:53:12.\n",
            "  Batch 5,000  of  9,774.    Elapsed: 0:53:37.\n",
            "  Batch 5,040  of  9,774.    Elapsed: 0:54:03.\n",
            "  Batch 5,080  of  9,774.    Elapsed: 0:54:29.\n",
            "  Batch 5,120  of  9,774.    Elapsed: 0:54:55.\n",
            "  Batch 5,160  of  9,774.    Elapsed: 0:55:20.\n",
            "  Batch 5,200  of  9,774.    Elapsed: 0:55:46.\n",
            "  Batch 5,240  of  9,774.    Elapsed: 0:56:12.\n",
            "  Batch 5,280  of  9,774.    Elapsed: 0:56:38.\n",
            "  Batch 5,320  of  9,774.    Elapsed: 0:57:03.\n",
            "  Batch 5,360  of  9,774.    Elapsed: 0:57:29.\n",
            "  Batch 5,400  of  9,774.    Elapsed: 0:57:55.\n",
            "  Batch 5,440  of  9,774.    Elapsed: 0:58:21.\n",
            "  Batch 5,480  of  9,774.    Elapsed: 0:58:46.\n",
            "  Batch 5,520  of  9,774.    Elapsed: 0:59:12.\n",
            "  Batch 5,560  of  9,774.    Elapsed: 0:59:38.\n",
            "  Batch 5,600  of  9,774.    Elapsed: 1:00:04.\n",
            "  Batch 5,640  of  9,774.    Elapsed: 1:00:30.\n",
            "  Batch 5,680  of  9,774.    Elapsed: 1:00:55.\n",
            "  Batch 5,720  of  9,774.    Elapsed: 1:01:21.\n",
            "  Batch 5,760  of  9,774.    Elapsed: 1:01:47.\n",
            "  Batch 5,800  of  9,774.    Elapsed: 1:02:12.\n",
            "  Batch 5,840  of  9,774.    Elapsed: 1:02:38.\n",
            "  Batch 5,880  of  9,774.    Elapsed: 1:03:04.\n",
            "  Batch 5,920  of  9,774.    Elapsed: 1:03:30.\n",
            "  Batch 5,960  of  9,774.    Elapsed: 1:03:55.\n",
            "  Batch 6,000  of  9,774.    Elapsed: 1:04:21.\n",
            "  Batch 6,040  of  9,774.    Elapsed: 1:04:47.\n",
            "  Batch 6,080  of  9,774.    Elapsed: 1:05:13.\n",
            "  Batch 6,120  of  9,774.    Elapsed: 1:05:38.\n",
            "  Batch 6,160  of  9,774.    Elapsed: 1:06:04.\n",
            "  Batch 6,200  of  9,774.    Elapsed: 1:06:30.\n",
            "  Batch 6,240  of  9,774.    Elapsed: 1:06:56.\n",
            "  Batch 6,280  of  9,774.    Elapsed: 1:07:21.\n",
            "  Batch 6,320  of  9,774.    Elapsed: 1:07:47.\n",
            "  Batch 6,360  of  9,774.    Elapsed: 1:08:13.\n",
            "  Batch 6,400  of  9,774.    Elapsed: 1:08:39.\n",
            "  Batch 6,440  of  9,774.    Elapsed: 1:09:04.\n",
            "  Batch 6,480  of  9,774.    Elapsed: 1:09:30.\n",
            "  Batch 6,520  of  9,774.    Elapsed: 1:09:56.\n",
            "  Batch 6,560  of  9,774.    Elapsed: 1:10:22.\n",
            "  Batch 6,600  of  9,774.    Elapsed: 1:10:47.\n",
            "  Batch 6,640  of  9,774.    Elapsed: 1:11:13.\n",
            "  Batch 6,680  of  9,774.    Elapsed: 1:11:39.\n",
            "  Batch 6,720  of  9,774.    Elapsed: 1:12:05.\n",
            "  Batch 6,760  of  9,774.    Elapsed: 1:12:30.\n",
            "  Batch 6,800  of  9,774.    Elapsed: 1:12:56.\n",
            "  Batch 6,840  of  9,774.    Elapsed: 1:13:22.\n",
            "  Batch 6,880  of  9,774.    Elapsed: 1:13:47.\n",
            "  Batch 6,920  of  9,774.    Elapsed: 1:14:13.\n",
            "  Batch 6,960  of  9,774.    Elapsed: 1:14:39.\n",
            "  Batch 7,000  of  9,774.    Elapsed: 1:15:05.\n",
            "  Batch 7,040  of  9,774.    Elapsed: 1:15:30.\n",
            "  Batch 7,080  of  9,774.    Elapsed: 1:15:56.\n",
            "  Batch 7,120  of  9,774.    Elapsed: 1:16:22.\n",
            "  Batch 7,160  of  9,774.    Elapsed: 1:16:48.\n",
            "  Batch 7,200  of  9,774.    Elapsed: 1:17:13.\n",
            "  Batch 7,240  of  9,774.    Elapsed: 1:17:39.\n",
            "  Batch 7,280  of  9,774.    Elapsed: 1:18:05.\n",
            "  Batch 7,320  of  9,774.    Elapsed: 1:18:31.\n",
            "  Batch 7,360  of  9,774.    Elapsed: 1:18:56.\n",
            "  Batch 7,400  of  9,774.    Elapsed: 1:19:22.\n",
            "  Batch 7,440  of  9,774.    Elapsed: 1:19:48.\n",
            "  Batch 7,480  of  9,774.    Elapsed: 1:20:14.\n",
            "  Batch 7,520  of  9,774.    Elapsed: 1:20:40.\n",
            "  Batch 7,560  of  9,774.    Elapsed: 1:21:05.\n",
            "  Batch 7,600  of  9,774.    Elapsed: 1:21:31.\n",
            "  Batch 7,640  of  9,774.    Elapsed: 1:21:57.\n",
            "  Batch 7,680  of  9,774.    Elapsed: 1:22:23.\n",
            "  Batch 7,720  of  9,774.    Elapsed: 1:22:48.\n",
            "  Batch 7,760  of  9,774.    Elapsed: 1:23:14.\n",
            "  Batch 7,800  of  9,774.    Elapsed: 1:23:40.\n",
            "  Batch 7,840  of  9,774.    Elapsed: 1:24:06.\n",
            "  Batch 7,880  of  9,774.    Elapsed: 1:24:32.\n",
            "  Batch 7,920  of  9,774.    Elapsed: 1:24:57.\n",
            "  Batch 7,960  of  9,774.    Elapsed: 1:25:23.\n",
            "  Batch 8,000  of  9,774.    Elapsed: 1:25:49.\n",
            "  Batch 8,040  of  9,774.    Elapsed: 1:26:15.\n",
            "  Batch 8,080  of  9,774.    Elapsed: 1:26:40.\n",
            "  Batch 8,120  of  9,774.    Elapsed: 1:27:06.\n",
            "  Batch 8,160  of  9,774.    Elapsed: 1:27:32.\n",
            "  Batch 8,200  of  9,774.    Elapsed: 1:27:58.\n",
            "  Batch 8,240  of  9,774.    Elapsed: 1:28:23.\n",
            "  Batch 8,280  of  9,774.    Elapsed: 1:28:49.\n",
            "  Batch 8,320  of  9,774.    Elapsed: 1:29:15.\n",
            "  Batch 8,360  of  9,774.    Elapsed: 1:29:41.\n",
            "  Batch 8,400  of  9,774.    Elapsed: 1:30:07.\n",
            "  Batch 8,440  of  9,774.    Elapsed: 1:30:32.\n",
            "  Batch 8,480  of  9,774.    Elapsed: 1:30:58.\n",
            "  Batch 8,520  of  9,774.    Elapsed: 1:31:24.\n",
            "  Batch 8,560  of  9,774.    Elapsed: 1:31:50.\n",
            "  Batch 8,600  of  9,774.    Elapsed: 1:32:15.\n",
            "  Batch 8,640  of  9,774.    Elapsed: 1:32:41.\n",
            "  Batch 8,680  of  9,774.    Elapsed: 1:33:07.\n",
            "  Batch 8,720  of  9,774.    Elapsed: 1:33:33.\n",
            "  Batch 8,760  of  9,774.    Elapsed: 1:33:59.\n",
            "  Batch 8,800  of  9,774.    Elapsed: 1:34:24.\n",
            "  Batch 8,840  of  9,774.    Elapsed: 1:34:50.\n",
            "  Batch 8,880  of  9,774.    Elapsed: 1:35:16.\n",
            "  Batch 8,920  of  9,774.    Elapsed: 1:35:42.\n",
            "  Batch 8,960  of  9,774.    Elapsed: 1:36:07.\n",
            "  Batch 9,000  of  9,774.    Elapsed: 1:36:33.\n",
            "  Batch 9,040  of  9,774.    Elapsed: 1:36:59.\n",
            "  Batch 9,080  of  9,774.    Elapsed: 1:37:25.\n",
            "  Batch 9,120  of  9,774.    Elapsed: 1:37:51.\n",
            "  Batch 9,160  of  9,774.    Elapsed: 1:38:16.\n",
            "  Batch 9,200  of  9,774.    Elapsed: 1:38:42.\n",
            "  Batch 9,240  of  9,774.    Elapsed: 1:39:08.\n",
            "  Batch 9,280  of  9,774.    Elapsed: 1:39:34.\n",
            "  Batch 9,320  of  9,774.    Elapsed: 1:40:00.\n",
            "  Batch 9,360  of  9,774.    Elapsed: 1:40:25.\n",
            "  Batch 9,400  of  9,774.    Elapsed: 1:40:51.\n",
            "  Batch 9,440  of  9,774.    Elapsed: 1:41:17.\n",
            "  Batch 9,480  of  9,774.    Elapsed: 1:41:43.\n",
            "  Batch 9,520  of  9,774.    Elapsed: 1:42:08.\n",
            "  Batch 9,560  of  9,774.    Elapsed: 1:42:34.\n",
            "  Batch 9,600  of  9,774.    Elapsed: 1:43:00.\n",
            "  Batch 9,640  of  9,774.    Elapsed: 1:43:25.\n",
            "  Batch 9,680  of  9,774.    Elapsed: 1:43:51.\n",
            "  Batch 9,720  of  9,774.    Elapsed: 1:44:17.\n",
            "  Batch 9,760  of  9,774.    Elapsed: 1:44:43.\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 1:44:52\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.37\n",
            "  Validation took: 0:03:45\n",
            "\n",
            "Training complete!\n",
            "Total training took 3:37:15 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlQ3dP6JWUMy",
        "colab_type": "text"
      },
      "source": [
        "### Step 7: Visualize Training Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD4C4QqXR-_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b495f645-1538-43f7-e37d-bba1cd506f73"
      },
      "source": [
        "#Make a dataframe of results. \n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.44</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.83</td>\n",
              "      <td>1:44:53</td>\n",
              "      <td>0:03:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1:44:52</td>\n",
              "      <td>0:03:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.44         0.36           0.83       1:44:53         0:03:46\n",
              "2               0.30         0.37           0.84       1:44:52         0:03:45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU00jJPFWZ6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "902a53d0-1404-4ffd-f8c8-5b2698035189"
      },
      "source": [
        "#Plot the results from the Dataframe\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj66rRTTXPB0",
        "colab_type": "text"
      },
      "source": [
        "### Step 8: Prep Dev Set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7lRfm72X4VE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "25474747-9230-4b8f-85cc-5a876f80e1b6"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#create the labels. \n",
        "d_impossible = extract_answer_type('dev-v2.0.json')\n",
        "d_impossible_df = pd.DataFrame(d_impossible) \n",
        "d_impossible_df.head()\n",
        "\n",
        "#pull out question data \n",
        "dq_text = extract_question('dev-v2.0.json')\n",
        "dq_df = pd.DataFrame(dq_text)\n",
        "dq_df.head()\n",
        "\n",
        "# #import Dev set. \n",
        "# dev_df = pd.read_csv('dev_with_split.csv')\n",
        "# #the empty choice is converted to a NaN when I reload, so this will correct the issue.\n",
        "# dev_df['a'].fillna(\"\", inplace=True)\n",
        "\n",
        "# print('Number of dev sentences: {:,}\\n'.format(dev_df.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56ddde6b9a695914005b9628</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "      <td>In what country is Normandy located?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56ddde6b9a695914005b9629</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "      <td>When were the Normans in Normandy?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56ddde6b9a695914005b962a</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "      <td>From which countries did the Norse originate?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56ddde6b9a695914005b962b</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "      <td>Who was the Norse leader?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56ddde6b9a695914005b962c</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "      <td>What century did the Normans first gain their ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          0  ...                                                  2\n",
              "0  56ddde6b9a695914005b9628  ...               In what country is Normandy located?\n",
              "1  56ddde6b9a695914005b9629  ...                 When were the Normans in Normandy?\n",
              "2  56ddde6b9a695914005b962a  ...      From which countries did the Norse originate?\n",
              "3  56ddde6b9a695914005b962b  ...                          Who was the Norse leader?\n",
              "4  56ddde6b9a695914005b962c  ...  What century did the Normans first gain their ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bUFtt0KK4j5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine into one data frame and save to CSV.\n",
        "dev_df = pd.concat([dq_df, d_impossible_df], axis = 1, sort = False)\n",
        "dev_df.columns = ['id', 'context', 'question', 'impossible']\n",
        "dev_df.head()\n",
        "dev_df.to_csv('dev_classification.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up4ydzU6LJUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bring a copy over into my drive so I can pick up here.\n",
        "\n",
        "%cp -R /content/dev_classification.csv /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QCtGHI3LN-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if just picking back off:\n",
        "\n",
        "dev_df = pd.read_csv('/content/drive/My Drive/dev_classification.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNTzPDlhfMNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pull out the relevant columns.\n",
        "\n",
        "contexts = dev_df.context.values\n",
        "questions = dev_df.question.values\n",
        "labels = dev_df.impossible.values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTxXkT3PemPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "#Add the question to the front of the contexts \n",
        "for i in range(len(questions)):\n",
        "    text = (str(questions[i])+' '+str(contexts[i]))\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Take to the max length\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',\n",
        "                        truncation = True)\n",
        "\n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# # Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', [0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3Ye7Y4cf1GW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9e7b14ef-501a-43ac-ef7d-25e95dcd0ce9"
      },
      "source": [
        "#Check the shape to make sure it worked correctly. \n",
        "print(input_ids.size(0))\n",
        "print(attention_masks.size(0))\n",
        "print(labels.size(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11873\n",
            "11873\n",
            "11873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqVe8OfDemNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the batch size.  \n",
        "batch_size = 8  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNg5M2QNXXbU",
        "colab_type": "text"
      },
      "source": [
        "### Step 9: Evaluate Dev Set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFbS9e0bX461",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2341abb5-68f2-4899-bbda-f1c3e93e27e8"
      },
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 11,873 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q40urDnUgYXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This will give me all 0's and 1's\n",
        "def get_label_list(predictions):\n",
        "  full_label_list = []\n",
        "  for i in range(len(predictions)):\n",
        "    for j in range(len(predictions[i])):\n",
        "      full_label_list.append((np.argmax(predictions[i], axis=1).flatten())[j])\n",
        "  return full_label_list\n",
        "\n",
        "full_labels = get_label_list(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iks-HKOlgYjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "11792528-3a42-4b7b-c779-f6e13e844a5d"
      },
      "source": [
        "# Necessary installs so I can mount the files from my bucket onto colab\n",
        "\n",
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   653  100   653    0     0  29681      0 --:--:-- --:--:-- --:--:-- 29681\n",
            "OK\n",
            "66 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 66 not upgraded.\n",
            "Need to get 4,278 kB of archives.\n",
            "After this operation, 12.8 MB of additional disk space will be used.\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 144465 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.30.0_amd64.deb ...\n",
            "Unpacking gcsfuse (0.30.0) ...\n",
            "Setting up gcsfuse (0.30.0) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdd6hSBlgJNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9b582e44-7e0f-4b02-a63e-e11e83b761d5"
      },
      "source": [
        "# Make a folder for the bucket, this will have all of the files inside. \n",
        "\n",
        "!mkdir folderOnColab\n",
        "!gcsfuse thaddeussegura_final_project folderOnColab "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using mount point: /content/folderOnColab\n",
            "Opening GCS connection...\n",
            "Opening bucket...\n",
            "Mounting file system...\n",
            "File system has been successfully mounted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlLg09EbkiXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_pred_dict(full_labels):\n",
        "#     pred_dict = {}\n",
        "#     for i in range(len(full_labels)):\n",
        "#         key = str(dev_df['id'][i])\n",
        "#         best_guess = str(dev_df.iloc[i, full_labels[i]])\n",
        "#         pred_dict[key] = best_guess\n",
        "#     return pred_dict \n",
        "\n",
        "def output_predictions(predictions):\n",
        "    with open('preds.json', 'w', encoding = 'utf-8') as json_file:\n",
        "        json.dump(predictions, json_file, ensure_ascii=True)\n",
        "\n",
        "def apply_classification(full_labels):\n",
        "  preds = open_json('predictions.json')\n",
        "  for i, id in enumerate(preds):\n",
        "    if full_labels[i] == 1:\n",
        "      preds[id] = \"\"\n",
        "  output_predictions(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ekMNeqhOL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apply_classification(full_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0RC14KxpCzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save a copy in my drive.\n",
        "\n",
        "%cp -R /content/preds.json /content/drive/My\\ Drive/classification_save "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxTBJ_gxpNBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "567331db-ad59-4a8f-9da9-72d29ed1ed31"
      },
      "source": [
        "# Clone SQUAD repo for the evaluation file.\n",
        "# Move the eval file to my content folder \n",
        "\n",
        "!git clone https://github.com/white127/SQUAD-2.0-bidaf.git\n",
        "%mv /content/SQUAD-2.0-bidaf/evaluate-v2.0.py /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SQUAD-2.0-bidaf'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Total 125 (delta 0), reused 0 (delta 0), pack-reused 125\u001b[K\n",
            "Receiving objects: 100% (125/125), 709.51 KiB | 647.00 KiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhqVVl0qqZYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "dced7bb5-fb7a-48a1-cde2-f263f5383d7b"
      },
      "source": [
        "# Still download the Dev set.\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-21 18:15:08--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.111.153, 185.199.109.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json.1’\n",
            "\n",
            "dev-v2.0.json.1     100%[===================>]   4.17M  13.0MB/s    in 0.3s    \n",
            "\n",
            "2020-07-21 18:15:08 (13.0 MB/s) - ‘dev-v2.0.json.1’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1w2J0GtpNGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e2015091-2407-4a29-ea9a-140030ed87f0"
      },
      "source": [
        "print(\"Results for Classification\")\n",
        "!python evaluate-v2.0.py dev-v2.0.json preds.json\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for Classification\n",
            "{\n",
            "  \"exact\": 75.36427187736882,\n",
            "  \"f1\": 78.37238782818865,\n",
            "  \"total\": 11873,\n",
            "  \"HasAns_exact\": 70.58029689608637,\n",
            "  \"HasAns_f1\": 76.60515531108051,\n",
            "  \"HasAns_total\": 5928,\n",
            "  \"NoAns_exact\": 80.13456686291,\n",
            "  \"NoAns_f1\": 80.13456686291,\n",
            "  \"NoAns_total\": 5945\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luE3KtO7Xb08",
        "colab_type": "text"
      },
      "source": [
        "### Step 10: Save Fine-Tuned Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISe-Pv-cW-LY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3ace17a6-e94f-40da-a599-7c21f9b29032"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/My Drive/classification_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/classification_save/model_state_dict.pth')\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "#torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/My Drive/classification_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/classification_save/vocab.txt',\n",
              " '/content/drive/My Drive/classification_save/special_tokens_map.json',\n",
              " '/content/drive/My Drive/classification_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}